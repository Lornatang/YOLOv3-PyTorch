[net]
# Testing
#batch = 1
#subdivisions = 1
# Training
batch = 64
subdivisions = 16
width = 416
height = 416
channels = 3
momentum = 0.9
decay = 0.0005
angle = 0
saturation = 1.5
exposure = 1.5
hue = .1

learning_rate = 0.001
burn_in = 1000
max_batches = 50200
policy = steps
steps = 40000,45000
scales = .1,.1

[convolutional]
batch_normalize = 1
filters = 16
size = 3
stride = 2
pad = 1
activation = hard_swish
# Layer:0 shape:208x208

# InvertedResidual 1
[convolutional]
batch_normalize = 1
filters = 16
size = 1
stride = 1
pad = 0
activation = relu
[convolutional]
batch_normalize = 1
filters = 16
size = 3
stride = 1
pad = 1
groups = 16
activation = linear
[shortcut]
from = -2
activation = linear

# InvertedResidual 2
[convolutional]
batch_normalize = 1
filters = 64
size = 1
stride = 1
pad = 0
activation = relu
[convolutional]
batch_normalize = 1
filters = 64
size = 3
stride = 2
pad = 1
groups = 64
activation = relu
# Layer:5 shape:104x104
[convolutional]
batch_normalize = 1
filters = 24
size = 1
stride = 1
pad = 0
activation = linear

# InvertedResidual 3
[convolutional]
batch_normalize = 1
filters = 72
size = 1
stride = 1
pad = 0
activation = relu
[convolutional]
batch_normalize = 1
filters = 72
size = 3
stride = 1
pad = 1
groups = 72
activation = relu
[convolutional]
batch_normalize = 1
filters = 24
size = 1
stride = 1
pad = 0
activation = linear
[shortcut]
from = -3
activation = linear

# InvertedResidual 4
[convolutional]
batch_normalize = 1
filters = 72
size = 1
stride = 1
pad = 0
activation = hard_swish
[convolutional]
batch_normalize = 1
filters = 72
size = 5
stride = 2
pad = 2
groups = 72
activation = hard_swish
# Layer:12 shape:52x52
[squeeze_excitation]
in_channels = 72
[convolutional]
batch_normalize = 1
filters = 40
size = 1
stride = 1
pad = 0
activation = linear

# InvertedResidual 5
[convolutional]
batch_normalize = 1
filters = 120
size = 1
stride = 1
pad = 0
activation = hard_swish
[convolutional]
batch_normalize = 1
filters = 120
size = 5
stride = 1
pad = 2
groups = 120
activation = hard_swish
[squeeze_excitation]
in_channels = 120
[convolutional]
batch_normalize = 1
filters = 40
size = 1
stride = 1
pad = 0
activation = linear
[shortcut]
from = -4
activation = linear

# InvertedResidual 6
[convolutional]
batch_normalize = 1
filters = 120
size = 1
stride = 1
pad = 0
activation = hard_swish
[convolutional]
batch_normalize = 1
filters = 120
size = 5
stride = 1
pad = 2
groups = 120
activation = hard_swish
[squeeze_excitation]
in_channels = 120
[convolutional]
batch_normalize = 1
filters = 40
size = 1
stride = 1
pad = 0
activation = linear
[shortcut]
from = -4
activation = linear

# InvertedResidual 7
[convolutional]
batch_normalize = 1
filters = 240
size = 1
stride = 1
pad = 0
activation = hard_swish
[convolutional]
batch_normalize = 1
filters = 240
size = 3
stride = 2
pad = 1
groups = 240
activation = hard_swish
# Layer:26 shape:26x26
[convolutional]
batch_normalize = 1
filters = 80
size = 1
stride = 1
pad = 0
activation = linear

# InvertedResidual 8
[convolutional]
batch_normalize = 1
filters = 200
size = 1
stride = 1
pad = 0
activation = hard_swish
[convolutional]
batch_normalize = 1
filters = 200
size = 3
stride = 1
pad = 1
groups = 200
activation = hard_swish
[convolutional]
batch_normalize = 1
filters = 80
size = 1
stride = 1
pad = 0
activation = linear
[shortcut]
from = -4
activation = linear

# InvertedResidual 9
[convolutional]
batch_normalize = 1
filters = 184
size = 1
stride = 1
pad = 0
activation = hard_swish
[convolutional]
batch_normalize = 1
filters = 184
size = 3
stride = 1
pad = 1
groups = 184
activation = hard_swish
[convolutional]
batch_normalize = 1
filters = 80
size = 1
stride = 1
pad = 0
activation = linear
[shortcut]
from = -4
activation = linear

# InvertedResidual 10
[convolutional]
batch_normalize = 1
filters = 184
size = 1
stride = 1
pad = 0
activation = hard_swish
[convolutional]
batch_normalize = 1
filters = 184
size = 3
stride = 1
pad = 1
groups = 184
activation = hard_swish
[convolutional]
batch_normalize = 1
filters = 80
size = 1
stride = 1
pad = 0
activation = linear
[shortcut]
from = -4
activation = linear

# InvertedResidual 11
[convolutional]
batch_normalize = 1
filters = 480
size = 1
stride = 1
pad = 0
activation = hard_swish
[convolutional]
batch_normalize = 1
filters = 480
size = 3
stride = 1
pad = 1
groups = 480
activation = hard_swish
[squeeze_excitation]
in_channels = 480
[convolutional]
batch_normalize = 1
filters = 112
size = 1
stride = 1
pad = 0
activation = linear

# InvertedResidual 12
[convolutional]
batch_normalize = 1
filters = 672
size = 1
stride = 1
pad = 0
activation = hard_swish
[convolutional]
batch_normalize = 1
filters = 672
size = 3
stride = 1
pad = 1
groups = 672
activation = hard_swish
[squeeze_excitation]
in_channels = 672
[convolutional]
batch_normalize = 1
filters = 112
size = 1
stride = 1
pad = 0
activation = linear
[shortcut]
from = -4
activation = linear

# InvertedResidual 13
[convolutional]
batch_normalize = 1
filters = 672
size = 1
stride = 1
pad = 0
activation = hard_swish
[convolutional]
batch_normalize = 1
filters = 672
size = 5
stride = 2
pad = 2
groups = 672
activation = hard_swish
# Layer:50 shape:13x13
[squeeze_excitation]
in_channels = 672
[convolutional]
batch_normalize = 1
filters = 160
size = 1
stride = 1
pad = 0
activation = linear

# InvertedResidual 14
[convolutional]
batch_normalize = 1
filters = 672
size = 1
stride = 1
pad = 0
activation = hard_swish
[convolutional]
batch_normalize = 1
filters = 672
size = 5
stride = 1
pad = 2
groups = 672
activation = hard_swish
[squeeze_excitation]
in_channels = 672
[convolutional]
batch_normalize = 1
filters = 160
size = 1
stride = 1
pad = 0
activation = linear
[shortcut]
from = -4
activation = linear

# InvertedResidual 15
[convolutional]
batch_normalize = 1
filters = 960
size = 1
stride = 1
pad = 0
activation = hard_swish
[convolutional]
batch_normalize = 1
filters = 960
size = 5
stride = 1
pad = 2
groups = 960
activation = hard_swish
[squeeze_excitation]
in_channels = 960
[convolutional]
batch_normalize = 1
filters = 160
size = 1
stride = 1
pad = 0
activation = linear
[shortcut]
from = -4
activation = linear

[convolutional]
batch_normalize = 1
filters = 960
size = 1
stride = 1
pad = 0
activation = hard_swish


###########
[convolutional]
batch_normalize = 1
filters = 256
size = 1
stride = 1
pad = 1
activation = leaky

[convolutional]
batch_normalize = 1
filters = 512
size = 3
stride = 1
pad = 1
activation = leaky

[convolutional]
size = 1
stride = 1
pad = 1
filters = 255
activation = linear

# prediction large object
# 13 * 13
[yolo]
mask = 3,4,5
anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319
classes = 80
num = 6
jitter = .3
ignore_thresh = .5
truth_thresh = 1
random = 1

[route]
layers = -4

[convolutional]
batch_normalize = 1
filters = 128
size = 1
stride = 1
pad = 1
activation = leaky

[upsample]
stride = 2

[route]
layers = -1, 48

[convolutional]
batch_normalize = 1
filters = 256
size = 3
stride = 1
pad = 1
activation = leaky

[convolutional]
size = 1
stride = 1
pad = 1
filters = 255
activation = linear

# prediction medium object
# 26 * 26
[yolo]
mask = 0,1,2
anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319
classes = 80
num = 6
jitter = .3
ignore_thresh = .7
truth_thresh = 1
random = 1